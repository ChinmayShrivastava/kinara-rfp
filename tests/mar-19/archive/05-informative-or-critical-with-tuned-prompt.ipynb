{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chinmayshrivastava/Documents/GitHub/kinara-rfp\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# moce two directories up and make that current directory\n",
    "os.chdir(\"../..\")\n",
    "# print current directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayshrivastava/Documents/GitHub/kinara-rfp/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from govrfp.rfpinsights._chromadb import return_collection, add_entries_to_collection\n",
    "path = \"tests/mar-19/data/\"\n",
    "critical_collection = return_collection(path=path, collection_name=\"critical\")\n",
    "informative_collection = return_collection(path=path, collection_name=\"informative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email DE-FOA-0003120@netl.doe.gov for questions about the FOA',\n",
       " 'Email EERE-eXCHANGE Support@hq.doe.gov for issues with EERE eXCHANGE, include FOA name and number in the subject line',\n",
       " 'Submit a Concept Paper by 5:00 PM ET on the due date to be eligible for a Full Application',\n",
       " 'Register and submit application materials through EERE eXCHANGE at https://eere-eXCHANGE.energy.gov/',\n",
       " 'Designate primary and backup points-of-contact in EERE eXCHANGE for communication during award negotiations']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read lines from \"tests/mar-19/01-compliances.txt\"\n",
    "with open(\"tests/mar-19/01-compliances.txt\", \"r\") as file:\n",
    "    compliances = file.readlines()\n",
    "    compliances = [compliance.strip() for compliance in compliances]\n",
    "compliances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return top n matching compliances\n",
    "def get_matching_compliances(critical_collection, query, n=5):\n",
    "    res = critical_collection.query(query_texts=[query], n_results=n)['documents'][0]\n",
    "    if len(res) == 0:\n",
    "        return \"Empty\"\n",
    "    return \"\\n\".join([f'- {t}' for t in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, your task is to accurately classify compliance items from a Request for Proposal (RFP) application. Assign a label of 0 to a compliance item if it is critical, mandatory, or directly impacts the application's functionality. This could be a hard requirement, soft requirement, or an explicitly defined requirement. Label it as 1 if it is optional, meaning it is not necessary but could enhance the application or is applicable in certain cases. Phrases like \"if applicable\" or \"upon request\" often indicate optional items. Assign -1 if the item is not a compliance requirement or if it is a duplicate of an item already listed. Be mindful of the context, implications, and nuances of the compliance items to accurately classify them. Pay attention to edge cases, such as duplicate items or items that may seem critical but are actually optional based on their implications.\n",
      "\n",
      "Attached list of compliance items:\n",
      "Empty\n",
      "\n",
      "Compliance Item:\n",
      "Email DE-FOA-0003120@netl.doe.gov for questions about the FOA\n",
      "\n",
      "Return 0, 1, or -1:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"As an AI language model, your task is to accurately classify compliance items from a Request for Proposal (RFP) application. Assign a label of 0 to a compliance item if it is critical, mandatory, or directly impacts the application's functionality. This could be a hard requirement, soft requirement, or an explicitly defined requirement. Label it as 1 if it is optional, meaning it is not necessary but could enhance the application or is applicable in certain cases. Phrases like \"if applicable\" or \"upon request\" often indicate optional items. Assign -1 if the item is not a compliance requirement or if it is a duplicate of an item already listed. Be mindful of the context, implications, and nuances of the compliance items to accurately classify them. Pay attention to edge cases, such as duplicate items or items that may seem critical but are actually optional based on their implications.\n",
    "\n",
    "Attached list of compliance items:\n",
    "{compliance_items}\n",
    "\n",
    "Compliance Item:\n",
    "{compliance_item}\n",
    "\n",
    "Return 0, 1, or -1:\"\"\"\n",
    "print(prompt.format(compliance_items=get_matching_compliances(critical_collection, compliances[0], n=10), compliance_item=compliances[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.complete(prompt.format(compliance_items=get_matching_compliances(critical_collection, compliances[0], 10), compliance_item=compliances[0])).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "critical_compliance = []\n",
    "informative_compliance = []\n",
    "other_compliance = []\n",
    "rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import something to cler the output\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937 362 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1459it [18:01,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, compliance in tqdm.tqdm(enumerate(compliances)):\n",
    "    # clear the output\n",
    "    clear_output(wait=True)\n",
    "    print(len(critical_compliance), len(informative_compliance), len(other_compliance))\n",
    "    try:\n",
    "        response = llm.complete(prompt.format(compliance_items=get_matching_compliances(critical_collection, compliance, n=15), compliance_item=compliance)).text\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        _rating = int(response)\n",
    "        rating.append(_rating)\n",
    "    except:\n",
    "        if '-1' in response:\n",
    "            _rating = -1\n",
    "            rating.append(_rating)\n",
    "        elif '0' in response:\n",
    "            _rating = 0\n",
    "            rating.append(_rating)\n",
    "        elif '1' in response:\n",
    "            _rating = 1\n",
    "            rating.append(_rating)\n",
    "        else:\n",
    "            print(response)\n",
    "            _rating = int(input(\"Enter the correct rating: \"))\n",
    "            rating.append(_rating)\n",
    "    if _rating == 0:\n",
    "        add_entries_to_collection(\n",
    "            docs=[compliance],\n",
    "            metadata=[{'id': f\"{index}\"}],\n",
    "            ids=[f\"{index}\"],\n",
    "            collection=critical_collection\n",
    "        )\n",
    "        critical_compliance.append(compliance)\n",
    "    elif _rating == 1:\n",
    "        add_entries_to_collection(\n",
    "            docs=[compliance],\n",
    "            metadata=[{'id': f\"{index}\"}],\n",
    "            ids=[f\"{index}\"],\n",
    "            collection=informative_collection\n",
    "        )\n",
    "        informative_compliance.append(compliance)\n",
    "    else:\n",
    "        other_compliance.append(compliance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export critical compliaces\n",
    "with open(\"tests/mar-19/new_critical_compliances.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(critical_compliance))\n",
    "\n",
    "# export informative compliaces\n",
    "with open(\"tests/mar-19/new_informative_compliances.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(informative_compliance))\n",
    "\n",
    "# export other compliaces\n",
    "with open(\"tests/mar-19/new_other_compliances.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(other_compliance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
